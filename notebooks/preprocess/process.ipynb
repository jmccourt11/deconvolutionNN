{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import sys\n",
    "import torch, torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "#from torchsummary import summary\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from tqdm import tqdm \n",
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "from numpy.fft import fftn, fftshift\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from matplotlib import colors\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from cupyx.scipy.signal import convolve2d as conv2\n",
    "# import cupy as cp\n",
    "\n",
    "# from scipy.signal import convolve2d as conv2np\n",
    "import random\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from multiprocessing import Pool, get_context\n",
    "from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import h5py\n",
    "import hdf5plugin\n",
    "\n",
    "#from utils.preprocessing_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(\u001b[38;5;18;43m__file__\u001b[39;49m))\n",
      "\u001b[1;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "sys.path.append(Path(\"Y:/ptychosaxs/deconvolutionNN\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"image.cmap\"] = \"jet\"\n",
    "\n",
    "#reduce size of diffraction patterns\n",
    "red=True\n",
    "\n",
    "#save model pth\n",
    "save=True\n",
    "\n",
    "# Setting path\n",
    "path = Path(\"Y:/ptychosaxs\")  # /net/micdata/data2/12IDC mounted windows drive\n",
    "#path=Path('/mnt/micdata2/12IDC/ptychosaxs') # micdata location 1 (refiner)\n",
    "#path=Path('/net/micdata/data2/12IDC/ptychosaxs') # micdata location 2 (refiner and artemis)\n",
    "\n",
    "# Join paths\n",
    "MODEL_SAVE_PATH = path / 'trained_model/' # Automatically adds the correct separator\n",
    "if (not os.path.isdir(MODEL_SAVE_PATH)):\n",
    "    os.mkdir(MODEL_SAVE_PATH)\n",
    "print(MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "num = 13# 13, scanned with 400, subtracted out probe; 12, scanned with 400 lattice; 11, 288 lattice size (2x other scanned samples); 10, scanned with scaled by q^4; 9, scanned with no pinhole extra convolution; 8, scanned sample, pinhole extra convolution; 5, cindy; 4, chansong\n",
    "data_location=path / f'data/diff_sim/{num}/'\n",
    "print(data_location)\n",
    "filenames=os.listdir(data_location)\n",
    "filenames=[data_location / f for f in filenames]\n",
    "\n",
    "# Combine into HDF5 (if not already done so)\n",
    "output_file=path / f\"data/combined_data_{num}.h5\"\n",
    "if output_file.exists():\n",
    "    print(f'combined file {output_file} already exists')\n",
    "else:\n",
    "    print('loading and writing to h5')\n",
    "    with h5py.File(output_file, \"w\") as h5f:\n",
    "        for i, file_path in enumerate(filenames):\n",
    "            data = np.load(file_path)\n",
    "            h5f.create_dataset(f\"convDP_{i}\", data=data[\"convDP\"])\n",
    "            h5f.create_dataset(f\"pinholeDP_{i}\", data=data[\"pinholeDP\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'h5py' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoading data...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Load data with progress bar\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mh5py\u001b[49m\u001b[38;5;241m.\u001b[39mFile(output_file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m h5f:\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# Get the keys (dataset names)\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     dataset_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(h5f\u001b[38;5;241m.\u001b[39mkeys()) \n\u001b[0;32m      7\u001b[0m     num_datasets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataset_keys) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m  \u001b[38;5;66;03m# Assuming convDP and pinholeDP pairs\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'h5py' is not defined"
     ]
    }
   ],
   "source": [
    "#load convoluted and ideal diffraction patterns\n",
    "print('Loading data...')\n",
    "# Load data with progress bar\n",
    "with h5py.File(output_file, \"r\") as h5f:\n",
    "    # Get the keys (dataset names)\n",
    "    dataset_keys = list(h5f.keys()) \n",
    "    num_datasets = len(dataset_keys) // 2  # Assuming convDP and pinholeDP pairs\n",
    "    print(f'{num_datasets} diffraction patterns')\n",
    "    # Initialize empty lists for the data\n",
    "    conv_DPs = []\n",
    "    pinhole_DPs = []\n",
    "\n",
    "    # Use tqdm for progress tracking\n",
    "    for i in tqdm(range(num_datasets), desc=\"Loading HDF5 datasets\"):\n",
    "        conv_DPs.append(h5f[f\"convDP_{i}\"][:])  # Load convDP dataset\n",
    "        pinhole_DPs.append(h5f[f\"pinholeDP_{i}\"][:])  # Load pinholeDP dataset\n",
    "\n",
    "# convert to np arrays\n",
    "conv_DPs=np.asarray(conv_DPs)\n",
    "ideal_DPs=np.asarray(pinhole_DPs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probe_DPs=np.ones(conv_DPs.shape) #dummy array for testing network with a probe\n",
    "#deal detector mask\n",
    "#chansong\n",
    "#conv_DPs=np.asarray([replace_2d_array_values_by_row_indices(replace_2d_array_values_by_row_indices(conv_DPs[i],ubound[0],ubound[1]),lbound[0],lbound[1]) for i in range(0,len(conv_DPs))])\n",
    "#cindy\n",
    "conv_DPs2=np.asarray([replace_2d_array_values_by_column_indices(replace_2d_array_values_by_column_indices(replace_2d_array_values_by_row_indices(replace_2d_array_values_by_row_indices(conv_DPs[i],0,8),247,255),0,8),247,255) for i in range(0,len(conv_DPs))])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ptychosaxsNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
