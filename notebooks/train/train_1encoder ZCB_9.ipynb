{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch, torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "#from torchsummary import summary\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "\n",
    "import sys\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "plt.rcParams[\"image.cmap\"] = \"jet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/net/micdata/data2/12IDC/ptychosaxs/trained_model\n"
     ]
    }
   ],
   "source": [
    "#save model pth\n",
    "save=True\n",
    "\n",
    "# Setting path\n",
    "path = Path(\"Y:/ptychosaxs\")  # /net/micdata/data2/12IDC mounted windows drive\n",
    "path = Path(\"/net/micdata/data2/12IDC/ptychosaxs/\")\n",
    "# Join paths\n",
    "MODEL_SAVE_PATH = path / 'trained_model/' # Automatically adds the correct separator\n",
    "if (not os.path.isdir(MODEL_SAVE_PATH)):\n",
    "    os.mkdir(MODEL_SAVE_PATH)\n",
    "print(MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed data\n",
    "num=17\n",
    "numDPs=10000\n",
    "amp_conv_red = np.load(os.path.abspath(os.path.join(os.getcwd(), f'../../data/processed/preprocessed_dir{num}_numDPs{numDPs}.npz')))['amp_conv_red']\n",
    "amp_ideal_red = np.load(os.path.abspath(os.path.join(os.getcwd(), f'../../data/processed/preprocessed_dir{num}_numDPs{numDPs}.npz')))['amp_ideal_red']\n",
    "amp_probe_red = np.load(os.path.abspath(os.path.join(os.getcwd(), f'../../data/processed/preprocessed_dir{num}_numDPs{numDPs}.npz')))['amp_probe_red']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500 2500 1250\n"
     ]
    }
   ],
   "source": [
    "# Set the number of patterns in test, train or validation set\n",
    "NTEST = amp_conv_red.shape[0]//4\n",
    "NTRAIN = amp_conv_red.shape[0]-NTEST\n",
    "NVALID = NTEST//2 # NTRAIN//\n",
    "\n",
    "print(NTRAIN,NTEST,NVALID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs: 4 Batch size: 64 Learning rate: 0.004\n",
      "256 256\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 64\n",
    "NGPUS = torch.cuda.device_count()\n",
    "BATCH_SIZE = NGPUS*16\n",
    "LR = NGPUS * 1e-3\n",
    "print(\"GPUs:\", NGPUS, \"Batch size:\", BATCH_SIZE, \"Learning rate:\", LR)\n",
    "\n",
    "no_probe=True\n",
    "H,W=amp_ideal_red[0].shape[0],amp_ideal_red[0].shape[1]\n",
    "print(H,W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7500, 1, 256, 256]) torch.Size([7500, 1, 256, 256]) torch.Size([7500, 1, 256, 256])\n",
      "6250 2 1250 2500\n"
     ]
    }
   ],
   "source": [
    "#separate data and convert to tensors and shuffle\n",
    "no_probe=True\n",
    "\n",
    "tst_start = amp_conv_red.shape[0]-NTEST\n",
    "\n",
    "X_train = amp_conv_red[:NTRAIN].reshape(-1,H,W)[:,np.newaxis,:,:]\n",
    "X_test = amp_conv_red[tst_start:].reshape(-1,H,W)[:,np.newaxis,:,:]\n",
    "\n",
    "Xp_train = amp_probe_red[:NTRAIN].reshape(-1,H,W)[:,np.newaxis,:,:]\n",
    "Xp_test = amp_probe_red[tst_start:].reshape(-1,H,W)[:,np.newaxis,:,:]\n",
    "\n",
    "Y_I_train = amp_ideal_red[:NTRAIN].reshape(-1,H,W)[:,np.newaxis,:,:]\n",
    "Y_I_test = amp_ideal_red[tst_start:].reshape(-1,H,W)[:,np.newaxis,:,:]\n",
    "\n",
    "ntrain=X_train.shape[0]\n",
    "ntest=X_test.shape[0]\n",
    "\n",
    "X_train, Xp_train, Y_I_train = shuffle(X_train, Xp_train, Y_I_train, random_state=0)\n",
    "\n",
    "#Training data\n",
    "X_train_tensor = torch.Tensor(X_train)\n",
    "Xp_train_tensor = torch.Tensor(Xp_train) \n",
    "Y_I_train_tensor = torch.Tensor(Y_I_train) \n",
    "\n",
    "#Test data\n",
    "X_test_tensor = torch.Tensor(X_test)\n",
    "Xp_test_tensor = torch.Tensor(Xp_test) \n",
    "Y_I_test_tensor = torch.Tensor(Y_I_test) \n",
    "\n",
    "print(X_train_tensor.shape,Xp_train_tensor.shape, Y_I_train_tensor.shape)\n",
    "\n",
    "\n",
    "if no_probe:\n",
    "    train_data = TensorDataset(X_train_tensor,Y_I_train_tensor)\n",
    "    test_data = TensorDataset(X_test_tensor,Xp_test_tensor)\n",
    "else:\n",
    "    train_data = TensorDataset(X_train_tensor,Xp_train_tensor,Y_I_train_tensor)\n",
    "    test_data = TensorDataset(X_test_tensor,Xp_test_tensor)\n",
    "\n",
    "\n",
    "N_TRAIN = X_train_tensor.shape[0]\n",
    "\n",
    "train_data2, valid_data = torch.utils.data.random_split(train_data,[N_TRAIN-NVALID,NVALID])\n",
    "print(len(train_data2),len(train_data2[0]),len(valid_data),len(test_data))\n",
    "\n",
    "\n",
    "#download and load training data\n",
    "trainloader = DataLoader(train_data2, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "\n",
    "validloader = DataLoader(valid_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "\n",
    "#same for test\n",
    "#download and load training data\n",
    "testloader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '../../src/models/'))) \n",
    "from encoder1 import recon_model\n",
    "\n",
    "model = recon_model()\n",
    "load_prev_model=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size: torch.Size([64, 1, 256, 256])\n",
      "torch.Size([64, 1, 256, 256])\n",
      "torch.float32\n",
      "Let's use 4 GPUs!\n",
      "DataParallel(\n",
      "  (module): recon_model(\n",
      "    (encoder1): Sequential(\n",
      "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU()\n",
      "    )\n",
      "    (encoder2): Sequential(\n",
      "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU()\n",
      "    )\n",
      "    (encoder3): Sequential(\n",
      "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU()\n",
      "    )\n",
      "    (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (drop): Dropout(p=0.5, inplace=False)\n",
      "    (bottleneck): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU()\n",
      "    )\n",
      "    (decoder4): Sequential(\n",
      "      (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU()\n",
      "    )\n",
      "    (decoder3): Sequential(\n",
      "      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU()\n",
      "    )\n",
      "    (decoder2): Sequential(\n",
      "      (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU()\n",
      "    )\n",
      "    (up_conv4): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (up_conv3): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (up_conv2): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (conv_last): Sequential(\n",
      "      (0): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "if no_probe:\n",
    "    for ampsI,ampsO in trainloader:\n",
    "        print(\"batch size:\", ampsI.shape)\n",
    "        amp = model(ampsI)#,ampsP)\n",
    "        print(amp.shape)\n",
    "        print(amp.dtype)\n",
    "        break\n",
    "else:\n",
    "    for ampsI,ampsP,ampsO in trainloader:\n",
    "        print(\"batch size:\", ampsI.shape)\n",
    "        amp = model(ampsI,ampsP)\n",
    "        print(amp.shape)\n",
    "        print(amp.dtype)\n",
    "        break    \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "    #model = nn.parallel.DistributedDataParallel(model) #Default all devices\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "model = model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.0\n",
      "LR step size is: 588.0 which is every 6 epochs\n"
     ]
    }
   ],
   "source": [
    "#Optimizer details\n",
    "iterations_per_epoch = np.floor((NTRAIN-NVALID)/BATCH_SIZE)+1 #Final batch will be less than batch size\n",
    "step_size = 6*iterations_per_epoch #Paper recommends 2-10 (6) number of iterations, step_size is half cycle\n",
    "print(iterations_per_epoch)\n",
    "print(\"LR step size is:\", step_size, \"which is every %d epochs\" %(step_size/iterations_per_epoch))\n",
    "\n",
    "\n",
    "\n",
    "criterion = nn.L1Loss()\n",
    "    \n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = LR, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=LR/10, max_lr=LR, step_size_up=step_size,\n",
    "                                              cycle_momentum=False, mode='triangular2')\n",
    "                                              \n",
    "                                              \n",
    "                                              #Function to update saved model if validation loss is minimum\n",
    "def update_saved_model(model, path):\n",
    "    if not os.path.isdir(path):\n",
    "        os.mkdir(path)\n",
    "    for f in os.listdir(path):\n",
    "        os.remove(os.path.join(path, f))\n",
    "    if (NGPUS>1):    \n",
    "        torch.save(model.module.state_dict(),path / 'best_model_ZCB_9.pth') #Have to save the underlying model else will always need 4 GPUs\n",
    "    else:\n",
    "        torch.save(model,path / 'best_model_ZCB_9.pth')\n",
    "\n",
    "def train(trainloader,metrics):\n",
    "    tot_loss = 0.0\n",
    "    loss_amp = 0.0\n",
    "    \n",
    "    for i, (ft_images,amps) in tqdm(enumerate(trainloader)):\n",
    "        ft_images = ft_images.to(device) #Move everything to device\n",
    "        amps = amps.to(device)\n",
    "        pred_amps = model(ft_images) #Forward pass\n",
    "        \n",
    "        #Compute losses\n",
    "        loss_a = criterion(pred_amps,amps) #Monitor amplitude loss\n",
    "        loss = loss_a #Use equiweighted amps and phase\n",
    "\n",
    "        #Zero current grads and do backprop\n",
    "        optimizer.zero_grad() \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        tot_loss += loss.detach().item()\n",
    "        loss_amp += loss_a.detach().item()\n",
    "\n",
    "        #Update the LR according to the schedule -- CyclicLR updates each batch\n",
    "        scheduler.step() \n",
    "        metrics['lrs'].append(scheduler.get_last_lr())\n",
    "        \n",
    "        \n",
    "    #Divide cumulative loss by number of batches-- sli inaccurate because last batch is different size\n",
    "    metrics['losses'].append([tot_loss/i,loss_amp/i]) \n",
    "\n",
    "def validate(validloader,metrics):\n",
    "    tot_val_loss = 0.0\n",
    "    val_loss_amp = 0.0\n",
    "    for j, (ft_images,amps) in enumerate(validloader):\n",
    "        ft_images = ft_images.to(device)\n",
    "        amps = amps.to(device)\n",
    "        pred_amps = model(ft_images) #Forward pass\n",
    "\n",
    "        val_loss_a = criterion(pred_amps,amps)\n",
    "        val_loss = val_loss_a\n",
    "    \n",
    "        tot_val_loss += val_loss.detach().item()\n",
    "        val_loss_amp += val_loss_a.detach().item()\n",
    "    metrics['val_losses'].append([tot_val_loss/j,val_loss_amp/j])\n",
    "  \n",
    "  #Update saved model if val loss is lower\n",
    "    if(tot_val_loss/j<metrics['best_val_loss']):\n",
    "        print(\"Saving improved model after Val Loss improved from %.5f to %.5f\" %(metrics['best_val_loss'],tot_val_loss/j))\n",
    "        metrics['best_val_loss'] = tot_val_loss/j\n",
    "        update_saved_model(model, MODEL_SAVE_PATH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "98it [00:12,  8.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving improved model after Val Loss improved from inf to 0.03099\n",
      "Epoch: 0 | Total  | Train Loss: 0.01895 | Val Loss: 0.03099\n",
      "Epoch: 0 | Amp | Train Loss: 0.01895 | Val Loss: 0.03099\n",
      "Epoch: 0 | Ending LR: 0.001000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "88it [00:09,  8.88it/s]"
     ]
    }
   ],
   "source": [
    "metrics = {'losses':[],'val_losses':[], 'lrs':[], 'best_val_loss' : np.inf}\n",
    "for epoch in range (EPOCHS):\n",
    "    \n",
    "  #Set model to train mode\n",
    "  model.train() \n",
    "  #Training loop\n",
    "  train(trainloader,metrics)\n",
    "    \n",
    "  #Switch model to eval mode\n",
    "  model.eval()\n",
    "    \n",
    "  #Validation loop\n",
    "  validate(validloader,metrics)\n",
    "  print('Epoch: %d | Total  | Train Loss: %.5f | Val Loss: %.5f' %(epoch, metrics['losses'][-1][0], metrics['val_losses'][-1][0]))\n",
    "  print('Epoch: %d | Amp | Train Loss: %.5f | Val Loss: %.5f' %(epoch, metrics['losses'][-1][1], metrics['val_losses'][-1][1]))\n",
    "  print('Epoch: %d | Ending LR: %.6f ' %(epoch, metrics['lrs'][-1][0])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = np.linspace(0,len(metrics['lrs']),len(metrics['lrs'])+1)\n",
    "epoch_list = batches/iterations_per_epoch\n",
    "\n",
    "plt.plot(epoch_list[1:],metrics['lrs'], 'C3-')\n",
    "plt.grid()\n",
    "plt.ylabel(\"Learning rate\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "\n",
    "\n",
    "losses_arr = np.array(metrics['losses'])\n",
    "val_losses_arr = np.array(metrics['val_losses'])\n",
    "losses_arr.shape\n",
    "fig, ax = plt.subplots(1,sharex=True, figsize=(15, 8))\n",
    "ax.plot(losses_arr[:,0], 'C3o-', label = \"Total Train loss\")\n",
    "ax.plot(val_losses_arr[:,0], 'C0o-', label = \"Total Val loss\")\n",
    "ax.set(ylabel='Loss')\n",
    "ax.grid()\n",
    "ax.legend(loc='center right', bbox_to_anchor=(1.5, 0.5))\n",
    "plt.tight_layout()\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "#model_new.eval() #imp when have dropout etc\n",
    "results = []\n",
    "for i, test in enumerate(testloader):\n",
    "    tests = test[0].to(device)\n",
    "    testsp = test[1].to(device)\n",
    "    result = model(tests)\n",
    "    for j in range(tests.shape[0]):\n",
    "        results.append(result[j].detach().to(\"cpu\").numpy())\n",
    "        \n",
    "results = np.array(results).squeeze()\n",
    "\n",
    "\n",
    "\n",
    "h,w = H,W\n",
    "ntest=results.shape[0]\n",
    "plt.figure()\n",
    "n = 5\n",
    "f,ax=plt.subplots(4,n,figsize=(15, 12))\n",
    "plt.gcf().text(0.02, 0.8, \"Input\", fontsize=20)\n",
    "plt.gcf().text(0.02, 0.6, \"True I\", fontsize=20)\n",
    "plt.gcf().text(0.02, 0.4, \"Predicted I\", fontsize=20)\n",
    "plt.gcf().text(0.02, 0.2, \"Difference I\", fontsize=20)\n",
    "\n",
    "for i in range(0,n):\n",
    "    j=int(round(np.random.rand()*ntest))\n",
    "\n",
    "    # display FT\n",
    "    im=ax[0,i].imshow(X_test[j].reshape(h, w))#,norm=colors.LogNorm())\n",
    "    plt.colorbar(im, ax=ax[0,i], format='%.2f')\n",
    "    ax[0,i].get_xaxis().set_visible(False)\n",
    "    ax[0,i].get_yaxis().set_visible(False)\n",
    "\n",
    "    # display original intens\n",
    "    im=ax[1,i].imshow(Y_I_test[j].reshape(h, w))#,norm=colors.LogNorm())\n",
    "    plt.colorbar(im, ax=ax[1,i], format='%.2f')\n",
    "    ax[1,i].get_xaxis().set_visible(False)\n",
    "    ax[1,i].get_yaxis().set_visible(False)\n",
    "    \n",
    "    # display predicted intens\n",
    "    im=ax[2,i].imshow(results[j].reshape(h, w))#,norm=colors.LogNorm())\n",
    "    plt.colorbar(im, ax=ax[2,i], format='%.2f')\n",
    "    ax[2,i].get_xaxis().set_visible(False)\n",
    "    ax[2,i].get_yaxis().set_visible(False)\n",
    "\n",
    "    #Difference in amplitude\n",
    "    im=ax[3,i].imshow(Y_I_test[j].reshape(h, w)-results[j].reshape(h, w))#,norm=colors.LogNorm())\n",
    "    plt.colorbar(im, ax=ax[3,i], format='%.2f')\n",
    "    ax[3,i].get_xaxis().set_visible(False)\n",
    "    ax[3,i].get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ptychosaxsNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
